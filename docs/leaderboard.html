<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Leaderboard · InventoryBench</title>
  <meta name="description" content="InventoryBench: a 1,320-instance benchmark for OR and LLM-based inventory agents on synthetic and real demand trajectories.">
  <link rel="stylesheet" href="assets/css/main.css">
</head>
<body>
  <header class="site-header">
    <div class="wrapper header-inner">
      <div class="site-branding">
        <a class="site-title" href="index.html">InventoryBench</a>
        <p class="site-tagline">Benchmark for OR- and LLM-based inventory agents</p>
      </div>
      <nav class="site-nav">
        <a href="index.html">Home</a>
        <a href="dataset.html">Dataset</a>
        <a href="leaderboard.html">Leaderboard</a>
      </nav>
    </div>
  </header>

  <main class="page-content">
    <div class="wrapper">
      <article class="page">
        <div class="page-content">
          <h1>Leaderboard</h1>
          <p>This page summarizes performance of OR baselines, LLM policies, and OR–LLM hybrids on <strong>InventoryBench</strong>.</p>
          <p>The primary evaluation metric is <strong>cumulative reward</strong> over the test period. We also report <strong>normalized reward</strong>, defined as the ratio between actual reward and a perfect‑foresight upper bound.</p>

          <h2>Overall leaderboard</h2>
          <p>The table below ranks all evaluated combinations of LLM and decision method by <strong>average normalized reward</strong> across all 1,320 benchmark instances. Higher is better, and 1.0 corresponds to the perfect‑foresight upper bound. Click column headers to sort by each metric.</p>

          <div id="leaderboard-container">
            <div class="table-wrapper">
              <table class="leaderboard-table" id="leaderboard-table">
                <thead>
                  <tr>
                    <th>Rank</th>
                    <th>Agent</th>
                    <th data-sort="overall" style="cursor: pointer;" title="Average normalized reward across all 1,320 instances">Overall Score ↕</th>
                    <th data-sort="real_0" style="cursor: pointer;" title="Real trajectories with known lead time (0 periods)">Real LT=0 ↕</th>
                    <th data-sort="real_4" style="cursor: pointer;" title="Real trajectories with known lead time (4 periods)">Real LT=4 ↕</th>
                    <th data-sort="real_stoch" style="cursor: pointer;" title="Real trajectories with stochastic lead time">Real Stoch ↕</th>
                    <th data-sort="synth_0" style="cursor: pointer;" title="Synthetic trajectories with known lead time (0 periods)">Synth LT=0 ↕</th>
                    <th data-sort="synth_4" style="cursor: pointer;" title="Synthetic trajectories with known lead time (4 periods)">Synth LT=4 ↕</th>
                    <th data-sort="synth_stoch" style="cursor: pointer;" title="Synthetic trajectories with stochastic lead time">Synth Stoch ↕</th>
                    <th>Details</th>
                  </tr>
                </thead>
                <tbody id="leaderboard-tbody">
                  <tr>
                    <td colspan="10" style="text-align: center; padding: 2rem;">Loading...</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <h2>Metric definition</h2>
          <p>For each instance, cumulative reward is:</p>
          <pre><code>Reward = Σ_t (profit_t × units_sold_t − holding_cost_t × units_held_t)</code></pre>
          <p>where:</p>
          <ul>
            <li><code>units_sold_t = min(demand_t, available_inventory_t)</code></li>
            <li><code>units_held_t</code> is the end‑of‑period on‑hand inventory.</li>
          </ul>
          <p>The <strong>perfect score</strong> assumes perfect knowledge of future demand and unlimited supply:</p>
          <pre><code>PerfectScore = Σ_t (demand_t × profit_t)</code></pre>
          <p>We report <strong>normalized reward</strong> as:</p>
          <pre><code>NormalizedReward = max(0, Reward / PerfectScore)</code></pre>
          <p>This normalizes performance across instances with different demand scales and cost parameters.</p>

          <h2>Method-level breakdown (per LLM × method)</h2>
          <p>For each row in the leaderboard, the detail page shows:</p>
          <ul>
            <li>The underlying model name (for example, <code>google/gemini-3-flash-preview</code>).</li>
            <li>Average normalized reward by dataset family:
              <ul>
                <li><code>synthetic_trajectory</code> (720 instances)</li>
                <li><code>real_trajectory</code> (600 instances)</li>
              </ul>
            </li>
            <li>Average normalized reward by lead‑time setting:
              <ul>
                <li><code>lead_time_0</code>, <code>lead_time_4</code>, <code>lead_time_stochastic</code></li>
              </ul>
            </li>
          </ul>
          <p>In future iterations we can further extend these pages with per‑instance tables and links into raw <code>benchmark_results.json</code> files.</p>

          <h2>Submission Guidelines</h2>
          <p>We welcome submissions of new methods to the InventoryBench leaderboard! To submit your method:</p>
          <ol>
            <li><strong>Implement your method</strong> following the benchmark interface for the 1,320 test instances.</li>
            <li><strong>Generate results</strong> including cumulative rewards and decisions for all instances across all 6 trajectory/lead-time categories.</li>
            <li><strong>Calculate metrics</strong> including mean normalized reward and standard errors for each category.</li>
            <li><strong>Create a detailed description</strong> of your approach in a README.md file.</li>
            <li><strong>Submit your results</strong> to the <a href="https://github.com/BrunoFu/OR_Agent" target="_blank" rel="noopener">InventoryBench repository</a> via a pull request, including:
              <ul>
                <li>results/{Method_Name}/benchmark_results.json</li>
                <li>results/{Method_Name}/scores.json</li>
                <li>results/{Method_Name}/README.md</li>
              </ul>
            </li>
          </ol>
          <p>Your method will be evaluated and added to the leaderboard upon acceptance. For more details, see the <a href="https://github.com/BrunoFu/OR_Agent" target="_blank" rel="noopener">project documentation on GitHub</a>.</p>
        </div>
      </article>
    </div>
  </main>

  <footer class="site-footer">
    <div class="wrapper footer-inner">
      <p class="footer-title">InventoryBench</p>
      <p class="footer-description">A 1,320-instance benchmark for OR and LLM-based inventory agents on synthetic and real demand trajectories.</p>
      <p class="footer-links">
        <a href="https://github.com/BrunoFu/OR_Agent" target="_blank" rel="noopener">Code &amp; Data on GitHub</a>
      </p>
    </div>
  </footer>

  <script>
    (function () {
      // Store original data and current sort state
      var allRows = [];
      var sortColumn = 'overall';
      var sortAscending = false;

      // Fetch and load leaderboard data
      fetch('leaderboard_data.json')
        .then(response => response.json())
        .then(data => {
          allRows = (data.methods || []).map(function(row) {
            return {
              original: row,
              display: {
                overall: Math.max(0, row.mean_ratio || 0),
                real_0: Math.max(0, (row.breakdowns && row.breakdowns['real_trajectory_lead_time_0']) ? row.breakdowns['real_trajectory_lead_time_0'].mean : 0),
                real_4: Math.max(0, (row.breakdowns && row.breakdowns['real_trajectory_lead_time_4']) ? row.breakdowns['real_trajectory_lead_time_4'].mean : 0),
                real_stoch: Math.max(0, (row.breakdowns && row.breakdowns['real_trajectory_lead_time_stochastic']) ? row.breakdowns['real_trajectory_lead_time_stochastic'].mean : 0),
                synth_0: Math.max(0, (row.breakdowns && row.breakdowns['synthetic_trajectory_lead_time_0']) ? row.breakdowns['synthetic_trajectory_lead_time_0'].mean : 0),
                synth_4: Math.max(0, (row.breakdowns && row.breakdowns['synthetic_trajectory_lead_time_4']) ? row.breakdowns['synthetic_trajectory_lead_time_4'].mean : 0),
                synth_stoch: Math.max(0, (row.breakdowns && row.breakdowns['synthetic_trajectory_lead_time_stochastic']) ? row.breakdowns['synthetic_trajectory_lead_time_stochastic'].mean : 0),
              }
            };
          });

          // Sort by overall descending initially
          allRows.sort(function(a, b) { return b.display.overall - a.display.overall; });

          renderTable();
          attachSortListeners();
        })
        .catch(error => {
          console.error('Error loading leaderboard data:', error);
          document.getElementById('leaderboard-tbody').innerHTML = '<tr><td colspan="10" style="text-align: center; color: red;">Error loading leaderboard data</td></tr>';
        });

      function renderTable() {
        var tbody = document.getElementById('leaderboard-tbody');
        tbody.innerHTML = '';

        allRows.forEach(function(row, index) {
          var tr = document.createElement('tr');
          var original = row.original;
          var display = row.display;

          var agentName;
          if (original.method_id === 'or') {
            agentName = 'OR (Base-stock)';
          } else {
            agentName = original.llm_label + ' (' + original.method_label + ')';
          }

          // Create detail link to specification detail page
          var detailFileName = original.folder_name
            .replace(/ /g, '_')
            .replace(/\(/g, '')
            .replace(/\)/g, '')
            .replace(/→/g, 'to') + '.html';
          var detailLink = '<a href="specifications/' + encodeURIComponent(detailFileName) + '">View</a>';

          tr.innerHTML =
            '<td>' + (index + 1) + '</td>' +
            '<td>' + agentName + '</td>' +
            '<td>' + display.overall.toFixed(4) + '</td>' +
            '<td>' + display.real_0.toFixed(4) + '</td>' +
            '<td>' + display.real_4.toFixed(4) + '</td>' +
            '<td>' + display.real_stoch.toFixed(4) + '</td>' +
            '<td>' + display.synth_0.toFixed(4) + '</td>' +
            '<td>' + display.synth_4.toFixed(4) + '</td>' +
            '<td>' + display.synth_stoch.toFixed(4) + '</td>' +
            '<td>' + detailLink + '</td>';

          tbody.appendChild(tr);
        });
      }

      function attachSortListeners() {
        var headers = document.querySelectorAll('th[data-sort]');
        headers.forEach(function(header) {
          header.addEventListener('click', function() {
            var column = this.getAttribute('data-sort');
            if (sortColumn === column) {
              sortAscending = !sortAscending;
            } else {
              sortColumn = column;
              sortAscending = false;
            }

            allRows.sort(function(a, b) {
              var aVal = a.display[sortColumn];
              var bVal = b.display[sortColumn];
              if (sortAscending) {
                return aVal - bVal;
              } else {
                return bVal - aVal;
              }
            });

            renderTable();
          });
        });
      }
    })();
  </script>
</body>
</html>
