{
  "instance_dir": "/shared/share_malatown/OR_Agent/examples/benchmark/synthetic_trajectory/lead_time_4/p03_mean_decrease/v3_100to30/r2_low",
  "instance_name": "r2_low",
  "promised_lead_time": 4,
  "model": "x-ai/grok-4.1-fast",
  "num_runs_llm": 1,
  "num_runs_deterministic": 1,
  "max_periods": null,
  "summary": {
    "perfect_score": 2620.0,
    "ratios": {
      "or": -1.9099236641221373,
      "llm": -2.58587786259542,
      "llm_to_or": -0.8003816793893129,
      "or_to_llm": -1.7255725190839695,
      "perfect_score": 1.0
    },
    "warnings": null
  },
  "results": {
    "or": {
      "rewards": [
        -5004.0
      ],
      "mean": -5004.0,
      "std": 0.0,
      "min": -5004.0,
      "max": -5004.0,
      "count": 1,
      "ratio_to_perfect": -1.9099236641221373
    },
    "llm": {
      "rewards": [
        -6775.0
      ],
      "mean": -6775.0,
      "std": 0.0,
      "min": -6775.0,
      "max": -6775.0,
      "count": 1,
      "ratio_to_perfect": -2.58587786259542
    },
    "llm_to_or": {
      "rewards": [
        -2097.0
      ],
      "mean": -2097.0,
      "std": 0.0,
      "min": -2097.0,
      "max": -2097.0,
      "count": 1,
      "ratio_to_perfect": -0.8003816793893129
    },
    "or_to_llm": {
      "rewards": [
        -4521.0
      ],
      "mean": -4521.0,
      "std": 0.0,
      "min": -4521.0,
      "max": -4521.0,
      "count": 1,
      "ratio_to_perfect": -1.7255725190839695
    },
    "perfect_score": {
      "rewards": [
        2620.0
      ],
      "mean": 2620.0,
      "std": 0.0,
      "min": 2620.0,
      "max": 2620.0,
      "count": 1,
      "ratio_to_perfect": 1.0
    }
  },
  "errors": {}
}